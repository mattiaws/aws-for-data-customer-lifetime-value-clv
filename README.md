# Using Customer Lifetime Value (CLV) to make data driven decisions

## Introduction


There are many key metrics that organizations focus on to make data driven decisions. Which includes, but not limited to, customer churn, customer spend, and may more. 

This sample code focuses on a business use-case to predict Customer Lifetime Value (CLV), which will improve the overall cost of engagement with the customers.

So what is Customer Lifetime Value (CLV). Customer lifetime value (CLV) is a measure of the total income a business can expect to bring in from a typical customer for as long as that person or account remains a client.

When measuring CLV, it’s best to look at the total average revenue generated by a customer and the total average profit. Each provides important insights into how customers interact with your business and if your overall marketing plan is working as expected.

For a more in-depth look, you may want to break down your company’s CLV by quartile or some other segmentation of customers. This can give greater insight into what’s working well with high-value customers, so you can work to replicate that success across your entire customer base.

## Architecture

A typical organization will have multiple data sources. Which will include data from Click-stream, Operational Databases like SQL server and Datawarehouse like Redshift, and then finally a data-lake which stores all the un-structured and semi-structured data.

In our sample solution, we are going to use Kinesis Data Streams to stream sample click-stream data. We are using SQL Server on Amazon RDS to represent one of the data sources, which needs to be migrated onto Amazon Aurora MYSQL.

We also have Amazon Redshift, which is our Datawarehousing Service. We are also using Redshift ML, which is a feature of Redshift and can help in creating machine learning models on top of the data in Amazon Redshift. This is fully automated and AI/ML knowledge is not needed. The model is created, trained and deployed using familiar SQL syntax.

In order to do an incremental load and also CDC (Change Data Capture), we are going to use Amazon Data Migration Service (DMS). 

Finally, for Business Intelligence (BI) and visualizations, we are using Amazon QuickSight, helping you gain value from your data.

![Architecture Diagram](https://user-images.githubusercontent.com/20495779/220314364-cff7fec7-e23f-4ea6-9996-a6a48d12e855.png)


## Implementation

To implement this solution, we are providing a cloud-formation script in this AWS Samples Github repository. However, there are some pre-reqs and some manual steps required in order to completely setup this demo environment. 

Also note that the data we are using for this demo is what we generated on our own. In future, we will run this setup on real data to be able to predict the CLV more accurately.

### Pre-Requisits

1. For the visualizations to work, you need to have Amazon Quicksight enabled on your AWS Account. To use `aws cli`, you can run the following command to enable Quicksight on your AWS Account:

`aws quicksight describe-account-subscription --aws-account-id <account-id>`

If it's not enabled, you can run the following command to enable it:

```
aws quicksight create-account-subscription --edition ENTERPRISE 
--authentication-method IAM_AND_QUICKSIGHT --aws-account-id XXXXXXXXXXXX 
--account-name quicksight-enterprise-reporting --notification-email XXXXXXXXXX 
--region us-west-2
```

2. Secondly, we have created a snapshot for the SQL Server on Amazon RDS, which will be deployed as part of the running the Amazon CloudFormation Template. This represents the server to be migrated to Amazon Aurora MySQL. That's the reason we have pre-loaded the data in this server.

3. Security is Job zero at AWS (Amazon Web Services), therefore, we are keep all the resources in private subnet. However, for Amazon QuickSight to access the Amazon Redshift cluster in Priave subnet, there is a manual step required to create VPC connection from Amazon QuickSight console.

Under the assets you will find two (2) CloudFormation templates. Let us give some additional information on those:

1. awsfordata-main-cf-stack.yaml
2. quicksight.yaml
3. kinesis data generator can be found here: 
    [Amazon Kinesis Data Generator](https://awslabs.github.io/amazon-kinesis-data-generator/web/help.htm)
    [Create a cognito user with CloudFormation](https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=Kinesis-Data-Generator-Cognito-User&templateURL=https://aws-kdg-tools.s3.us-west-2.amazonaws.com/cognito-setup.json)

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This library is licensed under the MIT-0 License. See the LICENSE file.
